{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from mpflash.mpboard_id.board_id import read_known_boardinfo\n",
    "\n",
    "from mpflash.mpboard_id.add_boards import boards_from_repo\n",
    "# import jsons\n",
    "\n",
    "from mpflash.vendor.board_database import Database\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# known_boards = read_known_boardinfo()\n",
    "# print(f\"Known boards: {len(known_boards)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpy_path = Path(\"../../micropython\")\n",
    "\n",
    "# all = boards_from_repo(mpy_path, version=\"\")\n",
    "\n",
    "# print(f\"All boards_from_repo: {len(all)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = Database(mpy_root_directory = mpy_path)\n",
    "\n",
    "\n",
    "# print(f\"Database boards: {len(db.boards)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boards = [(\n",
    "#             db.boards[b].port.name,\n",
    "#            db.boards[b].name,\n",
    "#            db.boards[b].mcu,\n",
    "#            ) for b in db.boards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def iter_boards(db: Database, version: str = \"\"):\n",
    "    version=version.strip()\n",
    "    for b in db.boards:\n",
    "        board = db.boards[b]\n",
    "        yield (\n",
    "           version,\n",
    "           board.name,\n",
    "           board.name,\n",
    "           board.mcu,\n",
    "           \"\", # no variant\n",
    "           board.path,\n",
    "           board.description,\n",
    "           \"\" # no text\n",
    "           )\n",
    "        if board.variants:\n",
    "            for v in board.variants:\n",
    "                yield (\n",
    "                   version,\n",
    "                    f\"{board.name}-{v.name}\",\n",
    "                    board.name,\n",
    "                    board.mcu,\n",
    "                    v.name,\n",
    "                    board.path,\n",
    "                    v.description,\n",
    "                    v.text\n",
    "                )\n",
    "\n",
    "# longlist = list(iter_boards(db))\n",
    "\n",
    "# print(f\"Database boards: {len(longlist)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "from typing import List\n",
    "\n",
    "from numpy import long\n",
    "import mpflash.basicgit as git\n",
    "from mpflash.versions import get_preview_mp_version, get_stable_mp_version, micropython_versions\n",
    "\n",
    "def get_boards(versions:List[str], mpy_dir:Path, ):\n",
    "    longlist = []\n",
    "    if not mpy_dir.is_dir():\n",
    "        print(f\"Directory {mpy_dir} not found\")\n",
    "    for version in versions:\n",
    "        print(\"-\" * 60)\n",
    "        build_nr = \"\"\n",
    "        if \"preview\" in version:\n",
    "            ok = git.checkout_tag(\"master\", mpy_dir)\n",
    "            if describe := git.get_git_describe(mpy_dir):\n",
    "                parts = describe.split(\"-\", 3)\n",
    "                if len( parts) >=3:\n",
    "                    build_nr = parts[2]\n",
    "        else:\n",
    "            ok = git.checkout_tag(version, mpy_dir)\n",
    "        if not ok:\n",
    "            print(f\"Failed to checkout {version} in {mpy_dir}\")\n",
    "            continue\n",
    "        \n",
    "        print( f\"{git.get_git_describe(mpy_dir)} - {build_nr}\")\n",
    "        # un-cached database \n",
    "        db = Database(mpy_dir)\n",
    "        shortlist = list(iter_boards(db, version=version))\n",
    "        print (f\"boards found {len(db.boards.keys())}\")\n",
    "        print (f\"boards-variants found {len(shortlist)}\")\n",
    "        longlist.extend(shortlist)\n",
    "    return longlist\n",
    "\n",
    "mpy_path = Path(\"../../micropython\")\n",
    "\n",
    "if False:\n",
    "    assert mpy_path.exists()\n",
    "    longlist = get_boards(\n",
    "        # versions = [\n",
    "        #     get_stable_mp_version(), \n",
    "        #     get_preview_mp_version(), \n",
    "        #     # \"preview\",\n",
    "        # ],\n",
    "        versions = micropython_versions(minver=\"1.9.4\"),\n",
    "        mpy_dir = mpy_path,\n",
    "        )        \n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total boards-variants: {len(longlist)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "csv_filename = 'micropython_boards.csv'\n",
    "zip_filename = 'micropython_boards.zip'\n",
    "\n",
    "if False:\n",
    "    columns = ['version', 'board_name', 'base_name', 'mcu', 'variant', 'path', 'description', 'text']\n",
    "    df = pd.DataFrame(longlist, columns=columns)\n",
    "\n",
    "    # Create a CSV file from the dataframe and compress it into a zip file\n",
    "\n",
    "    # Define output filenames\n",
    "    csv_filename = 'micropython_boards.csv'\n",
    "    zip_filename = 'micropython_boards_data.zip'\n",
    "\n",
    "    # Create the ZIP file and add the CSV data directly without creating an intermediate file\n",
    "    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        # Create a temporary in-memory CSV string\n",
    "        csv_data = df.to_csv(index=False)\n",
    "        # Write the CSV data directly to the zip file\n",
    "        zipf.writestr(csv_filename, csv_data)\n",
    "\n",
    "    # # For comparison, we'll still create the CSV file to measure compression\n",
    "    # df.to_csv(csv_filename, index=False)\n",
    "\n",
    "    # # Get file sizes to show compression ratio\n",
    "    # csv_size = os.path.getsize(csv_filename)\n",
    "    zip_size = os.path.getsize(zip_filename)\n",
    "    # compression_ratio = (1 - (zip_size / csv_size)) * 100\n",
    "\n",
    "    print(f\"ZIP file created: {zip_filename} ({zip_size:,} bytes)\")\n",
    "    # print(f\"CSV file created: {csv_filename} ({csv_size:,} bytes)\")\n",
    "    # print(f\"Compression ratio: {compression_ratio:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now open directly from the zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records stored in database from zip: 2256\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import io\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "# # Define the new database path\n",
    "db_path2 = 'temp_micropython_boards_from_zip.db'\n",
    "\n",
    "# Connect to the new database\n",
    "conn2 = sqlite3.connect(db_path2)\n",
    "\n",
    "conn2.row_factory = sqlite3.Row  # return rows as dicts\n",
    "# Create the same table schema\n",
    "conn2.execute('''\n",
    "CREATE TABLE IF NOT EXISTS boards (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    version TEXT,\n",
    "    board_name TEXT,\n",
    "    base_name TEXT,\n",
    "    mcu TEXT,\n",
    "    variant TEXT,\n",
    "    path TEXT,\n",
    "    description TEXT,\n",
    "    text TEXT\n",
    ")\n",
    "''')\n",
    "\n",
    "# Load data directly from the zip file\n",
    "with zipfile.ZipFile(zip_filename, 'r') as zipf:\n",
    "    # Read the CSV file from the zip\n",
    "    with zipf.open(csv_filename) as csv_file:\n",
    "        # Use pandas to read the CSV data\n",
    "        df_from_zip = pd.read_csv(io.TextIOWrapper(csv_file, 'utf-8'))\n",
    "        # Replace NaN values with empty strings to avoid NULL values in the database\n",
    "        df_from_zip = df_from_zip.fillna('')\n",
    "        # Insert data into the new SQLite database\n",
    "        df_from_zip.to_sql('boards', conn2, if_exists='replace', index=False)\n",
    "\n",
    "# Create indices for faster searching\n",
    "conn2.execute('CREATE INDEX IF NOT EXISTS idx_version ON boards (version)')\n",
    "conn2.execute('CREATE INDEX IF NOT EXISTS idx_board_name ON boards (board_name)')\n",
    "conn2.execute('CREATE INDEX IF NOT EXISTS idx_mcu ON boards (mcu)')\n",
    "\n",
    "conn2.commit()\n",
    "\n",
    "# Test retrieving some data\n",
    "cursor2 = conn2.cursor()\n",
    "cursor2.execute(\"SELECT COUNT(*) FROM boards\")\n",
    "record_count = cursor2.fetchone()[0]\n",
    "\n",
    "print(f\"Total records stored in database from zip: {record_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "import json\n",
    "\n",
    "class BoardVersion(BaseModel):\n",
    "    board_name: str\n",
    "    variant: str\n",
    "    description: str\n",
    "    versions: List[str]\n",
    "    path: str = \"\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_db_row(cls, row):\n",
    "        return cls(\n",
    "            board_name=row[\"board_name\"],\n",
    "            variant=row[\"variant\"],\n",
    "            description=row[\"description\"],\n",
    "            versions=json.loads(row[\"versions\"]),\n",
    "            path=row[\"path\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "    # conn = sqlite3.connect(db_path)\n",
    "    # conn.row_factory = sqlite3.Row  # Access columns by name\n",
    "    # cursor = conn.cursor()\n",
    "\n",
    "def get_board_versions(cursor, search_desc: str, search_variant: str) -> List[BoardVersion]:\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT DISTINCT\n",
    "        UPPER(board_name) as board_name,\n",
    "        UPPER(variant) as variant,\n",
    "        description,\n",
    "        json_group_array(version) as versions,\n",
    "        path\n",
    "    FROM boards\n",
    "    WHERE description LIKE ?\n",
    "    AND variant like ?\n",
    "    GROUP BY UPPER(board_name) , UPPER(variant), description;\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.execute(query, (search_desc, search_variant))\n",
    "    rows = cursor.fetchall()\n",
    "    # conn.close()\n",
    "\n",
    "    return [BoardVersion.from_db_row(row) for row in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for description: PYBv1.1 and variant: DP\n",
      "board_name='PYBV11-DP' variant='DP' description='PYBv1.1 with STM32F405RG' versions=['v1.18', 'v1.19', 'v1.19.1', 'v1.20.0', 'v1.21.0', 'v1.22.0', 'v1.22.1', 'v1.22.2', 'v1.23.0', 'v1.24.0', 'v1.24.1', 'v1.25.0-preview'] path='../../micropython/ports/stm32/boards/PYBV11'\n"
     ]
    }
   ],
   "source": [
    "# db_path = r\"d:\\mypython\\mpflash\\scripts\\micropython_boards_from_zip.db\"\n",
    "\n",
    "conn2.row_factory = sqlite3.Row  # return rows as dicts\n",
    "cursor = conn2.cursor()\n",
    "description = \"Pimoroni Pico LiPo\"#  16MB with RP2040\"\n",
    "variant = \"FLASH_16M\"\n",
    "\n",
    "description = \"PYBv1.1\"\n",
    "variant = \"DP\"\n",
    "\n",
    "descr = description.rsplit(\" with \",1)[0].strip()\n",
    "print(f\"Searching for description: {descr} and variant: {variant}\")\n",
    "results = get_board_versions(cursor, f\"{descr}%\", variant)\n",
    "\n",
    "\n",
    "for board in results:\n",
    "    print(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
