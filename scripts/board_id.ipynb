{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from mpflash.vendor.board_database import Database\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build boardlist from repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## iterator to flatten the board database into a list of tuples\n",
    "\n",
    "def iter_boards(db: Database, version: str = \"\"):\n",
    "    version=version.strip()\n",
    "    for b in db.boards:\n",
    "        board = db.boards[b]\n",
    "        yield (\n",
    "           version,\n",
    "           board.name,\n",
    "           board.name,\n",
    "           board.mcu,\n",
    "           \"\", # no variant\n",
    "           board.path.split(\"/micropython/\",1)[1], # TODO - remove hack\n",
    "           board.description,\n",
    "           \"\" # no text\n",
    "           )\n",
    "        if board.variants:\n",
    "            for v in board.variants:\n",
    "                yield (\n",
    "                   version,\n",
    "                    f\"{board.name}-{v.name}\",\n",
    "                    board.name,\n",
    "                    board.mcu,\n",
    "                    v.name,\n",
    "                    board.path.split(\"/micropython/\",1)[1], # TODO - remove hack\n",
    "                    v.description,\n",
    "                    v.text\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import mpflash.basicgit as git\n",
    "from mpflash.versions import get_preview_mp_version, get_stable_mp_version, micropython_versions\n",
    "\n",
    "def boardlist_from_repo(versions:List[str], mpy_dir:Path, ):\n",
    "    longlist = []\n",
    "    if not mpy_dir.is_dir():\n",
    "        print(f\"Directory {mpy_dir} not found\")\n",
    "    for version in versions:\n",
    "        print(\"-\" * 60)\n",
    "        build_nr = \"\"\n",
    "        if \"preview\" in version:\n",
    "            ok = git.checkout_tag(\"master\", mpy_dir)\n",
    "            if describe := git.get_git_describe(mpy_dir):\n",
    "                parts = describe.split(\"-\", 3)\n",
    "                if len( parts) >=3:\n",
    "                    build_nr = parts[2]\n",
    "        else:\n",
    "            ok = git.checkout_tag(version, mpy_dir)\n",
    "        if not ok:\n",
    "            print(f\"Failed to checkout {version} in {mpy_dir}\")\n",
    "            continue\n",
    "        \n",
    "        print( f\"{git.get_git_describe(mpy_dir)} - {build_nr}\")\n",
    "        # un-cached database \n",
    "        db = Database(mpy_dir)\n",
    "        shortlist = list(iter_boards(db, version=version))\n",
    "        print (f\"boards found {len(db.boards.keys())}\")\n",
    "        print (f\"boards-variants found {len(shortlist)}\")\n",
    "        longlist.extend(shortlist)\n",
    "    return longlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ports/esp32/boards/ESP32_GENERIC_C3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"../../micropython/ports/esp32/boards/ESP32_GENERIC_C3\".split(\"/micropython/\",1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpy_path = Path(\"../../micropython\")\n",
    "# testlist = boardlist_from_repo(\n",
    "#     versions = micropython_versions(minver=\"1.24.1\"), # older versions do not have the board.json files\n",
    "#     mpy_dir = mpy_path,\n",
    "#     )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-20 13:38:46.731\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mmpflash.basicgit\u001b[0m:\u001b[36m_run_local_git\u001b[0m:\u001b[36m61\u001b[0m - \u001b[33m\u001b[1mwarning: unable to rmdir 'lib/arduino-lib': Directory not empty\n",
      "warning: unable to rmdir 'lib/cyw43-driver': Directory not empty\n",
      "warning: unable to rmdir 'lib/micropython-lib': Directory not empty\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1.18-dirty - \n",
      "boards found 124\n",
      "boards-variants found 148\n",
      "------------------------------------------------------------\n",
      "v1.19-dirty - \n",
      "boards found 141\n",
      "boards-variants found 165\n",
      "------------------------------------------------------------\n",
      "v1.19.1-dirty - \n",
      "boards found 141\n",
      "boards-variants found 165\n",
      "------------------------------------------------------------\n",
      "v1.20.0-dirty - \n",
      "boards found 160\n",
      "boards-variants found 184\n",
      "------------------------------------------------------------\n",
      "v1.21.0-dirty - \n",
      "boards found 158\n",
      "boards-variants found 190\n",
      "------------------------------------------------------------\n",
      "v1.22.0-dirty - \n",
      "boards found 163\n",
      "boards-variants found 195\n",
      "------------------------------------------------------------\n",
      "v1.22.1-dirty - \n",
      "boards found 163\n",
      "boards-variants found 195\n",
      "------------------------------------------------------------\n",
      "v1.22.2-dirty - \n",
      "boards found 163\n",
      "boards-variants found 195\n",
      "------------------------------------------------------------\n",
      "v1.23.0-dirty - \n",
      "boards found 163\n",
      "boards-variants found 198\n",
      "------------------------------------------------------------\n",
      "v1.24.0-dirty - \n",
      "boards found 172\n",
      "boards-variants found 207\n",
      "------------------------------------------------------------\n",
      "v1.24.1-dirty - \n",
      "boards found 172\n",
      "boards-variants found 207\n",
      "------------------------------------------------------------\n",
      "v1.25.0-preview-81-g2c80d36998 - 81\n",
      "boards found 172\n",
      "boards-variants found 207\n",
      "============================================================\n",
      "Total boards-variants: 2256\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mpy_path = Path(\"../../micropython\")\n",
    "do_package = True\n",
    "\n",
    "if do_package:\n",
    "    assert mpy_path.exists()\n",
    "    longlist = boardlist_from_repo(\n",
    "        versions = micropython_versions(minver=\"1.18\"), # older versions do not have the board.json files\n",
    "        mpy_dir = mpy_path,\n",
    "        )        \n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total boards-variants: {len(longlist)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package the list of boards in a zipped csv for inclusion in the mpflash package \n",
    "withouth compression , or as a database it takes up too much space \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP file created: micropython_boards.zip (14,894 bytes)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "zip_file = 'micropython_boards.zip'\n",
    "csv_filename = 'micropython_boards.csv'\n",
    "\n",
    "if do_package:\n",
    "\n",
    "    columns = ['version', 'board_id', 'board_name', 'mcu', 'variant', 'path', 'description', 'text']\n",
    "    df = pd.DataFrame(longlist, columns=columns)\n",
    "\n",
    "    # Create the ZIP file and add the CSV data directly without creating an intermediate file\n",
    "    with zipfile.ZipFile(zip_file, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        # Create a temporary in-memory CSV string\n",
    "        csv_data = df.to_csv(index=False)\n",
    "        # Write the CSV data directly to the zip file\n",
    "        zipf.writestr(csv_filename, csv_data)\n",
    "\n",
    "\n",
    "    # # Get file sizes to show compression ratio\n",
    "    # csv_size = os.path.getsize(csv_filename)\n",
    "    zip_size = os.path.getsize(zip_file)\n",
    "    # compression_ratio = (1 - (zip_size / csv_size)) * 100\n",
    "\n",
    "    print(f\"ZIP file created: {zip_file} ({zip_size:,} bytes)\")\n",
    "    # print(f\"CSV file created: {csv_filename} ({csv_size:,} bytes)\")\n",
    "    # print(f\"Compression ratio: {compression_ratio:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create database from the zipped / boardlist.csv file\n",
    "\n",
    "\n",
    "Now open directly from the zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata\n",
    "\n",
    "\n",
    "from mpflash.config import config\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "def get_database_version(conn : sqlite3.Connection):\n",
    "    # Connect to the SQLite database and fetch the version\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "    # Create metadata table if it doesn't exist\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS metadata (\n",
    "        key TEXT PRIMARY KEY,\n",
    "        value TEXT\n",
    "    )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "    # Query for the 'version' key\n",
    "    cursor.execute(\"SELECT value FROM metadata WHERE key = ?\", ('version',))\n",
    "    # Result will be None if not found, otherwise will contain the value\n",
    "    value = value[0] if (value := cursor.fetchone()) else None\n",
    "    return value\n",
    "\n",
    "def set_database_version(conn : sqlite3.Connection, version:str):\n",
    "    # Connect to the SQLite database and set the version\n",
    "    with sqlite3.connect(config.db_path) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        # Create metadata table if it doesn't exist\n",
    "        cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS metadata (\n",
    "            key TEXT PRIMARY KEY,\n",
    "            value TEXT\n",
    "        )\n",
    "        ''')\n",
    "        conn.commit()\n",
    "        # Insert or replace the version value\n",
    "        cursor.execute(\"INSERT OR REPLACE INTO metadata (key, value) VALUES (?, ?)\", ('version', version))\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update boardlist from zip \n",
    "import zipfile\n",
    "import io\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def update_boardlist_from_zip(conn : sqlite3.Connection,zip_file: Path):\n",
    "    csv_filename = 'micropython_boards.csv' # name of the .csv inside the .zip \n",
    "\n",
    "    # Check if the zip file exists\n",
    "    if not zip_file.exists() or not zip_file.is_file():\n",
    "        print(f\"Zip file {zip_file} not found.\")\n",
    "        return\n",
    "    conn.row_factory = sqlite3.Row  # return rows as dicts\n",
    "\n",
    "    # Create the same table schema\n",
    "    conn.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS boards (\n",
    "        \"version\" TEXT NOT NULL,\n",
    "        \"board_id\" TEXT NOT NULL,\n",
    "        \"board_name\" TEXT,\n",
    "        \"mcu\" TEXT,\n",
    "        \"variant\" TEXT,\n",
    "        \"path\" TEXT,\n",
    "        \"description\" TEXT,\n",
    "        \"text\" TEXT,\n",
    "        PRIMARY KEY(version, board_id)\n",
    "    )\n",
    "    ''')\n",
    "\n",
    "    # Load data directly from the zip file\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zipf:\n",
    "        # Read the CSV file from the zip\n",
    "        with zipf.open(csv_filename) as csv_file:\n",
    "            # Use pandas to read the CSV data\n",
    "            df_boardlist = pd.read_csv(io.TextIOWrapper(csv_file, 'utf-8'))\n",
    "            # Replace NaN values with empty strings to avoid NULL values in the database\n",
    "            df_boardlist = df_boardlist.fillna('')\n",
    "            # Insert data into the new SQLite database\n",
    "            df_boardlist.to_sql('boards', conn, if_exists='replace', index=False)\n",
    "\n",
    "    # Create indices for faster searching\n",
    "    conn.execute('CREATE INDEX IF NOT EXISTS idx_version ON boards (version)')\n",
    "    conn.execute('CREATE INDEX IF NOT EXISTS idx_id_version ON boards (board_id,version)')\n",
    "    # conn.execute('CREATE INDEX IF NOT EXISTS idx_board_id ON boards (board_id)')\n",
    "    # conn.execute('CREATE INDEX IF NOT EXISTS idx_board_name ON boards (board_name)')\n",
    "    conn.execute('CREATE INDEX IF NOT EXISTS idx_descr ON boards (description)')\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create database \n",
    "- check version  of the data \n",
    "- update the data \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Migrate json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmlrpc.client import boolean\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def load_jsonl_to_sqlite_pandas(jsonl_path: Path, conn: sqlite3.Connection, table_name = 'downloads',):\n",
    "    \"\"\"\n",
    "    Load a JSONL file into a SQLite database using pandas.\n",
    "    \n",
    "    Args:\n",
    "        jsonl_path (str or Path): Path to the JSONL file\n",
    "        db_path (str or Path): Path to the SQLite database\n",
    "    \n",
    "    Returns:\n",
    "        int: Number of records imported\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure file exists\n",
    "    if not jsonl_path.exists():\n",
    "        raise FileNotFoundError(f\"JSONL file not found: {jsonl_path}\")\n",
    "    \n",
    "    # Read JSONL file into pandas DataFrame\n",
    "    print(\"Reading JSONL file into DataFrame...\")\n",
    "    df = pd.read_json(jsonl_path, lines=True)\n",
    "    record_count = len(df)\n",
    "    \n",
    "    if record_count == 0:\n",
    "        print(\"JSONL file is empty\")\n",
    "        return 0\n",
    "    # clean up the column names and data\n",
    "    # Replace NaN values with empty strings to avoid NULL values in the database\n",
    "    df = df.fillna('')\n",
    "    #remove the url column\n",
    "    if 'url' in df.columns:\n",
    "        df = df.drop(columns=['url'])\n",
    "    # rename the variant column to board_id\n",
    "    if 'variant' in df.columns:\n",
    "        df = df.rename(columns={'variant': 'board_id'})\n",
    "    if 'firmware' in df.columns:\n",
    "        df = df.rename(columns={'firmware': 'source'})\n",
    "\n",
    "    # # change the preview and custom columns to boolean\n",
    "    # for col in ['custom', 'preview']:\n",
    "    #     if col in df.columns:\n",
    "    #         df[col] = df[col].astype(bool)\n",
    "    # Convert filename paths to POSIX format\n",
    "    if 'filename' in df.columns:\n",
    "        df['filename'] = df['filename'].apply(lambda x: Path(x).as_posix() if x else '')\n",
    "\n",
    "    # append '-preview' to the version column if preview is True\n",
    "    if 'preview' in df.columns:\n",
    "        df['version'] = df.apply(lambda row: f\"{row['version']}-preview\" if row['preview'] else row['version'], axis=1)\n",
    "        df = df.drop(columns=['preview'])\n",
    "\n",
    "     \n",
    "    # Write DataFrame to SQLite\n",
    "    print(f\"Writing {record_count} records to database...\")\n",
    "    df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "    \n",
    "    # Create indices for faster searching\n",
    "    cursor = conn.cursor()\n",
    "    for col in df.columns:\n",
    "        if col.lower() in ['board_id', 'filename', 'version']:\n",
    "            cursor.execute(f'CREATE INDEX IF NOT EXISTS idx_dl_{col} ON {table_name} (\"{col}\")')\n",
    "    \n",
    "    conn.commit()\n",
    "    \n",
    "    print(f\"Successfully imported {record_count} records\")\n",
    "    return record_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_views(conn: sqlite3.Connection):\n",
    "    \"\"\"\n",
    "    Create views for the SQLite database.\n",
    "    \n",
    "    Args:\n",
    "        conn (sqlite3.Connection): SQLite connection object\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    views = {\n",
    "        'latest_boards': '''\n",
    "            SELECT b.*, d.version, d.filename, d.source\n",
    "            FROM boards b\n",
    "            LEFT JOIN downloads d ON b.board_id = d.board_id AND b.version = d.version\n",
    "        ''',\n",
    "        \"boards_downloaded\" : \"\"\"\n",
    "            SELECT \n",
    "                b.board_id,\n",
    "                b.description,\n",
    "                b.version as board_version,\n",
    "                d.version as download_version,\n",
    "                d.build,\n",
    "                d.filename\n",
    "\n",
    "            FROM\n",
    "                boards b\n",
    "            left JOIN \n",
    "                downloads d \n",
    "            ON \n",
    "                b.board_id = d.board_id\n",
    "                AND d.version LIKE b.version || '%'\n",
    "            ORDER BY\n",
    "                d.version DESC,\n",
    "                d.build DESC,\n",
    "                d.board_id\n",
    "        \"\"\",\n",
    "        \"board_variants_versions\" : \"\"\"\n",
    "        SELECT \n",
    "            UPPER(board_name) as board_name,\n",
    "            json_group_array (DISTINCT UPPER(variant)) AS variants,\n",
    "            json_group_array (DISTINCT (version)) AS versions\n",
    "        FROM boards\n",
    "        GROUP BY UPPER(board_name)\n",
    "        ORDER BY UPPER(board_name)\n",
    "        \"\"\",\n",
    "        \"board_id_versions\" : \"\"\"\n",
    "        SELECT \n",
    "            UPPER(board_id) as board_id,\n",
    "            json_group_array (DISTINCT (version)) AS versions\n",
    "        FROM boards\n",
    "        GROUP BY UPPER(board_id)\n",
    "        ORDER BY UPPER(board_id)\n",
    "        \"\"\"\n",
    "\n",
    "    }\n",
    "\n",
    "    # Drop existing views if they exist\n",
    "    for view_name in views:\n",
    "        cursor.execute(f'DROP VIEW IF EXISTS {view_name}')\n",
    "\n",
    "    # Create new views\n",
    "    for view_name, query in views.items():\n",
    "        cursor.execute(f'CREATE VIEW {view_name} AS {query}')\n",
    "\n",
    "    \n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records stored in database from zip: 2256\n",
      "Reading JSONL file into DataFrame...\n",
      "Writing 91 records to database...\n",
      "Successfully imported 91 records\n",
      "Total records imported: 91\n"
     ]
    }
   ],
   "source": [
    "# combine all the above\n",
    "\n",
    "import sqlite3\n",
    "from packaging.version import Version\n",
    "\n",
    "with sqlite3.connect(config.db_path) as conn:\n",
    "    if not get_database_version(conn):\n",
    "        set_database_version(conn, \"0.1\")\n",
    "    current = get_database_version(conn)\n",
    "    if Version(current) < Version(\"1.24.1\"):\n",
    "        zip_file = Path(\"micropython_boards.zip\")\n",
    "        update_boardlist_from_zip(conn, zip_file)\n",
    "\n",
    "        # Create/update views\n",
    "        create_views(conn)\n",
    "\n",
    "        # set_database_version(conn, \"1.24.1\")\n",
    "\n",
    "    # Test retrieving some data\n",
    "    cursor2 = conn.cursor()\n",
    "    cursor2.execute(\"SELECT COUNT(*) FROM boards\")\n",
    "    record_count = cursor2.fetchone()[0]\n",
    "\n",
    "    print(f\"Total records stored in database from zip: {record_count}\")\n",
    "\n",
    "    # Execute the function\n",
    "    jsonl_path = config.firmware_folder /  \"firmware.jsonl\"\n",
    "    record_count = load_jsonl_to_sqlite_pandas(jsonl_path, conn)\n",
    "    print(f\"Total records imported: {record_count}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "import json\n",
    "\n",
    "class BoardVersion(BaseModel):\n",
    "    board_id: str\n",
    "    variant: str\n",
    "    description: str\n",
    "    versions: List[str]\n",
    "    path: str = \"\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_db_row(cls, row):\n",
    "        return cls(\n",
    "            board_id=row[\"board_id\"],\n",
    "            variant=row[\"variant\"],\n",
    "            description=row[\"description\"],\n",
    "            versions=json.loads(row[\"versions\"]),\n",
    "            path=row[\"path\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "    # conn = sqlite3.connect(db_path)\n",
    "    # conn.row_factory = sqlite3.Row  # Access columns by name\n",
    "    # cursor = conn.cursor()\n",
    "\n",
    "def get_board_versions(cursor, search_desc: str, search_variant: str) -> List[BoardVersion]:\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT DISTINCT\n",
    "        UPPER(board_id) as board_id,\n",
    "        UPPER(variant) as variant,\n",
    "        description,\n",
    "        json_group_array(version) as versions,\n",
    "        path\n",
    "    FROM boards\n",
    "    WHERE description LIKE ?\n",
    "    AND variant like ?\n",
    "    GROUP BY UPPER(board_id) , UPPER(variant), description;\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.execute(query, (search_desc, search_variant))\n",
    "    rows = cursor.fetchall()\n",
    "    # conn.close()\n",
    "\n",
    "    return [BoardVersion.from_db_row(row) for row in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # db_path = r\"d:\\mypython\\mpflash\\scripts\\micropython_boards_from_zip.db\"\n",
    "\n",
    "# conn2.row_factory = sqlite3.Row  # return rows as dicts\n",
    "# cursor = conn2.cursor()\n",
    "# description = \"Pimoroni Pico LiPo\"#  16MB with RP2040\"\n",
    "# variant = \"FLASH_16M\"\n",
    "\n",
    "# description = \"PYBv1.1\"\n",
    "# variant = \"DP\"\n",
    "\n",
    "# descr = description.rsplit(\" with \",1)[0].strip()\n",
    "# print(f\"Searching for description: {descr} and variant: {variant}\")\n",
    "# results = get_board_versions(cursor, f\"{descr}%\", variant)\n",
    "\n",
    "\n",
    "# for board in results:\n",
    "#     print(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
